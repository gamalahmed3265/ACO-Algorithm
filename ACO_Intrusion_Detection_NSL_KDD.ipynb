{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ant Colony Optimization algorithm  (ACOA) as an optimizer for training a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle # saving and loading trained model\n",
    "from os import path\n",
    "\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing library for support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "# importing library for K-neares-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# importing library for Linear Discriminant Analysis Model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# importing library for Quadratic Discriminant Analysis Model\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
    "from sklearn.metrics import classification_report # for generating a classification report of model\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from keras.layers import Dense # importing dense layer\n",
    "from keras.models import Sequential #importing Sequential layer\n",
    "from keras.models import model_from_json # saving and loading trained model\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# representation of model layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numpy.random import choice as np_choice\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>intrusion</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>normal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.782367</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.620982</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-1.161030</td>\n",
       "      <td>-1.035688</td>\n",
       "      <td>-1.321428</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.339648</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.809857</td>\n",
       "      <td>-1.389669</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.690846</td>\n",
       "      <td>-0.184522</td>\n",
       "      <td>-0.189235</td>\n",
       "      <td>-0.572083</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.472521</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>125968</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-1.184947</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>125969</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>0.977304</td>\n",
       "      <td>1.159389</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>125970</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>0.979238</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.893738</td>\n",
       "      <td>-0.773724</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>125971</td>\n",
       "      <td>0.523041</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-1.094207</td>\n",
       "      <td>-0.972455</td>\n",
       "      <td>-1.366922</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>125972</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.492801</td>\n",
       "      <td>-0.349162</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     count  srv_serror_rate  serror_rate  \\\n",
       "0                0 -0.717045        -0.631929    -0.637209   \n",
       "1                1 -0.620982        -0.631929    -0.637209   \n",
       "2                2  0.339648         1.605104     1.602664   \n",
       "3                3 -0.690846        -0.184522    -0.189235   \n",
       "4                4 -0.472521        -0.631929    -0.637209   \n",
       "...            ...       ...              ...          ...   \n",
       "125968      125968  0.872361         1.605104     1.602664   \n",
       "125969      125969 -0.717045        -0.631929    -0.637209   \n",
       "125970      125970 -0.725778        -0.631929    -0.637209   \n",
       "125971      125971  0.523041         1.605104     1.602664   \n",
       "125972      125972 -0.725778        -0.631929    -0.637209   \n",
       "\n",
       "        dst_host_serror_rate  dst_host_srv_serror_rate  logged_in  \\\n",
       "0                  -0.639532                 -0.624871  -0.809262   \n",
       "1                  -0.639532                 -0.624871  -0.809262   \n",
       "2                   1.608759                  1.618955  -0.809262   \n",
       "3                  -0.572083                 -0.602433   1.235694   \n",
       "4                  -0.639532                 -0.624871   1.235694   \n",
       "...                      ...                       ...        ...   \n",
       "125968              1.608759                  1.618955  -0.809262   \n",
       "125969             -0.639532                 -0.624871  -0.809262   \n",
       "125970              0.979238                 -0.624871   1.235694   \n",
       "125971              1.608759                  1.618955  -0.809262   \n",
       "125972             -0.639532                 -0.624871   1.235694   \n",
       "\n",
       "        dst_host_same_srv_rate  dst_host_srv_count  same_srv_rate  ...  \\\n",
       "0                    -0.782367           -0.818890       0.771283  ...   \n",
       "1                    -1.161030           -1.035688      -1.321428  ...   \n",
       "2                    -0.938287           -0.809857      -1.389669  ...   \n",
       "3                     1.066401            1.258754       0.771283  ...   \n",
       "4                     1.066401            1.258754       0.771283  ...   \n",
       "...                        ...                 ...            ...  ...   \n",
       "125968               -0.938287           -0.818890      -1.184947  ...   \n",
       "125969                0.977304            1.159389       0.771283  ...   \n",
       "125970               -0.893738           -0.773724       0.771283  ...   \n",
       "125971               -1.094207           -0.972455      -1.366922  ...   \n",
       "125972               -0.492801           -0.349162       0.771283  ...   \n",
       "\n",
       "        flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  intrusion  \\\n",
       "0             0        0        0        0        1        0          1   \n",
       "1             0        0        0        0        1        0          1   \n",
       "2             1        0        0        0        0        0          0   \n",
       "3             0        0        0        0        1        0          1   \n",
       "4             0        0        0        0        1        0          1   \n",
       "...         ...      ...      ...      ...      ...      ...        ...   \n",
       "125968        1        0        0        0        0        0          0   \n",
       "125969        0        0        0        0        1        0          1   \n",
       "125970        0        0        0        0        1        0          1   \n",
       "125971        1        0        0        0        0        0          0   \n",
       "125972        0        0        0        0        1        0          1   \n",
       "\n",
       "        abnormal  normal     label  \n",
       "0              0       1    normal  \n",
       "1              0       1    normal  \n",
       "2              1       0  abnormal  \n",
       "3              0       1    normal  \n",
       "4              0       1    normal  \n",
       "...          ...     ...       ...  \n",
       "125968         1       0  abnormal  \n",
       "125969         0       1    normal  \n",
       "125970         0       1    normal  \n",
       "125971         1       0  abnormal  \n",
       "125972         0       1    normal  \n",
       "\n",
       "[125973 rows x 98 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"datasets/bin_data.csv\"\n",
    "bin_data=pd.read_csv(path)\n",
    "bin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Imkkjtu_Fnzr"
   },
   "outputs": [],
   "source": [
    "X = bin_data.iloc[:,0:93].values # dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
    "Y = bin_data[['intrusion']].values # target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gNx0tOV7FwfO"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset 75% for training and 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9-5ChLnLEVqn"
   },
   "outputs": [],
   "source": [
    "def Fobj():\n",
    "    mlp = Sequential() # creating model\n",
    "    # adding input layer and first layer with 50 neurons\n",
    "    # X_train.shape is (94479, 93)\n",
    "    mlp.add(Dense(units=33, input_dim=X_train.shape[1], activation='relu'))#50x93=4650\n",
    "    # output layer with sigmoid activation\n",
    "    mlp.add(Dense(units=1,activation='sigmoid'))\n",
    "    return mlp\n",
    "# len(Fobj().get_weights()[1])\n",
    "# Fobj().get_weights()[0].flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=Fobj()\n",
    "# defining loss function, optimizer, metrics and then compiling model\n",
    "mlp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "dim=0;\n",
    "for i in range(len(mlp.get_weights())):# 4 for 4 array \n",
    "    dim=dim+mlp.get_weights()[i].flatten().shape[0]# 4650+50+50+1=4751\n",
    "# dim = 4751\n",
    "# print(math.sqrt(dim))\n",
    "N=20# Population size\n",
    "X=np.zeros((N,dim)) #(20, 4751)\n",
    "# print(X[:,:3])\n",
    "Fit=np.ones(N)*float('inf') #(20, 1)\n",
    "# print(Fit.reshape(N,1))\n",
    "bF=float('inf')\n",
    "bPos=[];\n",
    "# print(len(mlp.get_weights()))#4\n",
    "# len(mlp.layers)#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wights and bias Y=XW+bias \n",
    "def setWeights(X):\n",
    "    Len=0\n",
    "    # X is each row data in datasets X and len is 4751\n",
    "    # len(mlp.layers is 2 each contain 4 array\n",
    "    for i in range(0,len(mlp.layers)):\n",
    "#         get Wights first from layers\n",
    "        a=mlp.layers[i].get_weights()[0].shape\n",
    "        weights=X[Len:(Len+mlp.layers[i].get_weights()[0].flatten().shape[0])]\n",
    "        weights=np.reshape(weights,a) \n",
    "        Len=Len+mlp.layers[i].get_weights()[0].flatten().shape[0]\n",
    "#         get bias first from layers\n",
    "        a=mlp.layers[i].get_weights()[1].shape\n",
    "        bias=X[Len:(Len+mlp.layers[i].get_weights()[1].flatten().shape[0])]\n",
    "        bias=np.reshape(bias,a)\n",
    "        Len=Len+mlp.layers[i].get_weights()[1].flatten().shape[0]\n",
    "        mlp.layers[i].set_weights([weights,bias])\n",
    "#         print(len(mlp.get_weights()))#4\n",
    "#         len(mlp.layers)#4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_boundaries(X):\n",
    "    for j in range(dim):\n",
    "        if X[j]>U_bounds:\n",
    "            X[j]=(L_bounds+np.random.random(1)*(U_bounds-L_bounds))\n",
    "        elif  X[j]<L_bounds:\n",
    "            X[j]=(L_bounds+np.random.random(1)*(U_bounds-L_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_bounds=0;\n",
    "U_bounds=1;\n",
    "def initialization():\n",
    "    for i in range(N):\n",
    "        for j in range(dim):\n",
    "            X[i][j]=(L_bounds+np.random.rand(1)*(U_bounds-L_bounds))\n",
    "        setWeights(X[i,:])\n",
    "        print(\"------------Solution \",i,\"-------------\")\n",
    "        score=mlp.evaluate(X_train, y_train, verbose = 1) \n",
    "        Fit[i]= score[0]#loss\n",
    "        print(score[1])#accurcy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get numner node visted and probility\n",
    "def pick_move(distances,pheromone, visited,alpha=1,beta=1):\n",
    "    all_inds = range(len(distances))\n",
    "    pheromone = np.copy(pheromone)\n",
    "    # print(pheromone)\n",
    "    pheromone[list(visited)] = 0\n",
    "    # print(pheromone[list(visited)])\n",
    "    row = pheromone ** alpha * (( 1.0 / distances) ** beta)\n",
    "    # h=f\"\"\"\n",
    "    # {pheromone} ** {alpha} * (( 1.0 / {dist}) ** {beta})\n",
    "    # \"\"\"\n",
    "    # print(h)\n",
    "    # print(row)\n",
    "    norm_row = row / row.sum()#probility\n",
    "    # print(norm_row)\n",
    "    move = np_choice(all_inds, 1, p=norm_row)[0]\n",
    "    return move #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get path each node\n",
    "def gen_path(distances,pheromone,start=0):\n",
    "    path = []\n",
    "    visited = set()\n",
    "    visited.add(start)\n",
    "    prev = start\n",
    "    for i in range(len(distances) - 1):\n",
    "        move = pick_move(distances[prev],pheromone[prev], visited)\n",
    "        path.append((prev, move))\n",
    "        prev = move\n",
    "        visited.add(move)\n",
    "        # print(f\"move: {move} prev:{prev} visited: {visited}\")\n",
    "        # print(f\"-- path {path}\")\n",
    "    path.append((prev, start)) # going back to where we started   \n",
    "    # print(f\"path {path}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance each node\n",
    "def gen_path_dist(distances,path):\n",
    "    total_dist = 0\n",
    "    # get values shortest path after\n",
    "    total_value=list()\n",
    "    for ele in path:\n",
    "          total_value.append(distances[ele])\n",
    "          total_dist +=distances[ele]\n",
    "    #     print(f\"{ele} : {distances[ele]}\")\n",
    "    # print(f\"total_dist: {total_dist}\")\n",
    "    return total_dist,total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance each node and path in all_path\n",
    "def gen_all_paths(distances,pheromone,n_ants):\n",
    "    all_paths = []\n",
    "    for i in range(n_ants):\n",
    "        path = gen_path(distances,pheromone)\n",
    "        genPathDist,_=gen_path_dist(distances,path)\n",
    "        all_paths.append((path, genPathDist))\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_pheronome(distances,pheromone ,all_paths, n_best, shortest_path):\n",
    "    # sorted the paths by distance\n",
    "    sorted_paths = sorted(all_paths, key=lambda x: x[1])\n",
    "    # print(f\"sorted_paths : {sorted_paths}\")\n",
    "    for path, dist in sorted_paths[:n_best]:\n",
    "        for move in path:\n",
    "            #update pheromone values \n",
    "            pheromone[move] += 1.0 / distances[move]\n",
    "    return pheromone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(distances, n_ants, n_best, n_iterations, decay):\n",
    "    all_inds = range(len(distances))\n",
    "    pheromone = np.ones(distances.shape) / len(distances)\n",
    "    shortest_path = None\n",
    "    all_time_shortest_path = (\"placeholder\", np.inf)\n",
    "    for i in range(n_iterations):\n",
    "        #get distance each node and path in all_path\n",
    "        all_paths = gen_all_paths(distances,pheromone,n_ants)\n",
    "        # print(f\"all_paths : {all_paths}\")\n",
    "        pheromone=spread_pheronome(distances,pheromone ,all_paths, n_best, shortest_path=shortest_path)\n",
    "        shortest_path = min(all_paths, key=lambda x: x[1])\n",
    "#         print (shortest_path)\n",
    "        # swap the smallest value of shortest_path\n",
    "        if shortest_path[1] < all_time_shortest_path[1]:\n",
    "            all_time_shortest_path = shortest_path            \n",
    "        pheromone = pheromone * decay \n",
    "    return all_time_shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACO():\n",
    "    initialization()\n",
    "    print(X.shape)\n",
    "    Max_iter=5;\n",
    "    eo=list()\n",
    "    bF=float('inf')\n",
    "    bPos=[]\n",
    "    for i in range(5):\n",
    "        if Fit[i]<bF:\n",
    "            bF=Fit[i]\n",
    "            bPos=copy.copy(X[i]);\n",
    "    t=0\n",
    "    \n",
    "    while t<Max_iter:\n",
    "        for i in range(N):\n",
    "#             NewX=copy.copy(X[i])\n",
    "            distances=X[i].reshape((56,56))\n",
    "#         print(distances)\n",
    "            shortest_path = run(distances, 1, 1, 5, 0.95)\n",
    "#             print (\"shorted_path: {}\".format(shortest_path))\n",
    "#             print(\"$\"*70)\n",
    "#             print(shortest_path[0])\n",
    "#             print(\"*\"*40)\n",
    "            _,shortest_path_value=gen_path_dist(distances,shortest_path[0])\n",
    "#             print(shortest_path_value)\n",
    "#             print(\"*\"*40)\n",
    "            for s in range(len(shortest_path_value)): #56\n",
    "#                 print(s)\n",
    "                X[i][s]=shortest_path_value[s]\n",
    "#             print(len(shortest_path_value))\n",
    "            \n",
    "#             print(\"*\"*40)\n",
    "#             check_boundaries(NewX)\n",
    "            setWeights(X[i])\n",
    "            score = mlp.evaluate(X_train, y_train, verbose = 0)\n",
    "            print(\"Accuracy:\",score[1],\" Loss: \",score[0])\n",
    "            newFit= score[0]\n",
    "            if newFit<Fit[i]:\n",
    "                Fit[i]=newFit\n",
    "#                 X[i]=copy.copy(X);\n",
    "            if Fit[i]<bF:\n",
    "                bF=Fit[i]\n",
    "                bPos=copy.copy(X[i]);\n",
    "        t=t+1;\n",
    "        print(\"The best so-far Fitness value obtained by ACO at iteration \",t,\"==\",bF)\n",
    "    eo.append(bF);\n",
    "    eo.append(bPos)\n",
    "    return eo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Solution  0 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 178990.2812 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  1 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 207131.8125 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  2 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 207310.8281 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  3 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 239594.4531 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  4 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 199463.0312 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  5 -------------\n",
      "2953/2953 [==============================] - 8s 3ms/step - loss: 314875.4688 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  6 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 255405.6406 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  7 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 265385.3125 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  8 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 265785.5625 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  9 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 227735.2031 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  10 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 277062.9688 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  11 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 161428.6875 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  12 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 211428.2656 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  13 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 181012.7188 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  14 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 218007.6094 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  15 -------------\n",
      "2953/2953 [==============================] - 7s 2ms/step - loss: 282592.3438 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  16 -------------\n",
      "2953/2953 [==============================] - 7s 2ms/step - loss: 238318.5312 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  17 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 291428.8438 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  18 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 288220.5000 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  19 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 264109.6875 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "(20, 3136)\n",
      "Accuracy: 0.535240650177002  Loss:  53225.0234375\n",
      "Accuracy: 0.535240650177002  Loss:  56202.5625\n",
      "Accuracy: 0.535240650177002  Loss:  79175.6875\n",
      "Accuracy: 0.535240650177002  Loss:  55702.80078125\n",
      "Accuracy: 0.535240650177002  Loss:  45934.40625\n",
      "Accuracy: 0.535240650177002  Loss:  113664.578125\n",
      "Accuracy: 0.535240650177002  Loss:  85265.28125\n",
      "Accuracy: 0.535240650177002  Loss:  70810.7109375\n",
      "Accuracy: 0.535240650177002  Loss:  84083.421875\n",
      "Accuracy: 0.535240650177002  Loss:  61954.296875\n",
      "Accuracy: 0.535240650177002  Loss:  59166.0625\n",
      "Accuracy: 0.535240650177002  Loss:  52551.48046875\n",
      "Accuracy: 0.535240650177002  Loss:  56250.75\n",
      "Accuracy: 0.535240650177002  Loss:  77401.328125\n",
      "Accuracy: 0.535240650177002  Loss:  72327.671875\n",
      "Accuracy: 0.535240650177002  Loss:  58106.3984375\n",
      "Accuracy: 0.535240650177002  Loss:  77444.3984375\n",
      "Accuracy: 0.535240650177002  Loss:  41428.50390625\n",
      "Accuracy: 0.535240650177002  Loss:  78591.0234375\n",
      "Accuracy: 0.535240650177002  Loss:  44649.50390625\n",
      "The best so-far Fitness value obtained by ACO at iteration  1 == 41428.50390625\n",
      "Accuracy: 0.535240650177002  Loss:  61042.5546875\n",
      "Accuracy: 0.535240650177002  Loss:  60795.26953125\n",
      "Accuracy: 0.535240650177002  Loss:  44330.05859375\n",
      "Accuracy: 0.535240650177002  Loss:  72239.4453125\n",
      "Accuracy: 0.535240650177002  Loss:  51140.36328125\n",
      "Accuracy: 0.535240650177002  Loss:  102377.640625\n",
      "Accuracy: 0.535240650177002  Loss:  76237.296875\n",
      "Accuracy: 0.535240650177002  Loss:  61885.2421875\n",
      "Accuracy: 0.535240650177002  Loss:  28354.599609375\n",
      "Accuracy: 0.535240650177002  Loss:  41962.9140625\n",
      "Accuracy: 0.535240650177002  Loss:  65740.25\n",
      "Accuracy: 0.535240650177002  Loss:  36214.23828125\n",
      "Accuracy: 0.535240650177002  Loss:  66945.59375\n",
      "Accuracy: 0.535240650177002  Loss:  57480.14453125\n",
      "Accuracy: 0.535240650177002  Loss:  39631.31640625\n",
      "Accuracy: 0.535240650177002  Loss:  100402.3984375\n",
      "Accuracy: 0.535240650177002  Loss:  57509.38671875\n",
      "Accuracy: 0.535240650177002  Loss:  46189.6953125\n",
      "Accuracy: 0.535240650177002  Loss:  72264.890625\n",
      "Accuracy: 0.535240650177002  Loss:  39066.75\n",
      "The best so-far Fitness value obtained by ACO at iteration  2 == 28354.599609375\n",
      "Accuracy: 0.535240650177002  Loss:  66710.4296875\n",
      "Accuracy: 0.535240650177002  Loss:  53240.890625\n",
      "Accuracy: 0.535240650177002  Loss:  77160.1953125\n",
      "Accuracy: 0.535240650177002  Loss:  59076.57421875\n",
      "Accuracy: 0.535240650177002  Loss:  71308.7109375\n",
      "Accuracy: 0.535240650177002  Loss:  98909.375\n",
      "Accuracy: 0.535240650177002  Loss:  66265.9453125\n",
      "Accuracy: 0.535240650177002  Loss:  46882.91796875\n",
      "Accuracy: 0.535240650177002  Loss:  38036.484375\n",
      "Accuracy: 0.535240650177002  Loss:  58604.13671875\n",
      "Accuracy: 0.535240650177002  Loss:  67345.46875\n",
      "Accuracy: 0.535240650177002  Loss:  47955.59375\n",
      "Accuracy: 0.535240650177002  Loss:  44034.171875\n",
      "Accuracy: 0.535240650177002  Loss:  56257.4296875\n",
      "Accuracy: 0.535240650177002  Loss:  47718.703125\n",
      "Accuracy: 0.535240650177002  Loss:  78532.1796875\n",
      "Accuracy: 0.535240650177002  Loss:  64313.0625\n",
      "Accuracy: 0.535240650177002  Loss:  59526.7109375\n",
      "Accuracy: 0.535240650177002  Loss:  39682.33984375\n",
      "Accuracy: 0.535240650177002  Loss:  41095.72265625\n",
      "The best so-far Fitness value obtained by ACO at iteration  3 == 28354.599609375\n",
      "Accuracy: 0.535240650177002  Loss:  63750.046875\n",
      "Accuracy: 0.535240650177002  Loss:  86043.6953125\n",
      "Accuracy: 0.535240650177002  Loss:  75574.8046875\n",
      "Accuracy: 0.535240650177002  Loss:  55658.75390625\n",
      "Accuracy: 0.535240650177002  Loss:  27820.17578125\n",
      "Accuracy: 0.535240650177002  Loss:  71878.7734375\n",
      "Accuracy: 0.535240650177002  Loss:  75912.7890625\n",
      "Accuracy: 0.535240650177002  Loss:  75635.28125\n",
      "Accuracy: 0.535240650177002  Loss:  73081.6875\n",
      "Accuracy: 0.535240650177002  Loss:  51284.33203125\n",
      "Accuracy: 0.535240650177002  Loss:  50434.7734375\n",
      "Accuracy: 0.535240650177002  Loss:  43617.0\n",
      "Accuracy: 0.535240650177002  Loss:  52177.703125\n",
      "Accuracy: 0.535240650177002  Loss:  34378.19140625\n",
      "Accuracy: 0.535240650177002  Loss:  50301.015625\n",
      "Accuracy: 0.535240650177002  Loss:  66135.0234375\n",
      "Accuracy: 0.535240650177002  Loss:  43921.4765625\n",
      "Accuracy: 0.535240650177002  Loss:  68524.515625\n",
      "Accuracy: 0.535240650177002  Loss:  97900.8203125\n",
      "Accuracy: 0.535240650177002  Loss:  54798.6953125\n",
      "The best so-far Fitness value obtained by ACO at iteration  4 == 27820.17578125\n",
      "Accuracy: 0.535240650177002  Loss:  66920.078125\n",
      "Accuracy: 0.535240650177002  Loss:  41216.33984375\n",
      "Accuracy: 0.535240650177002  Loss:  38027.9140625\n",
      "Accuracy: 0.535240650177002  Loss:  54603.16015625\n",
      "Accuracy: 0.535240650177002  Loss:  36290.65234375\n",
      "Accuracy: 0.535240650177002  Loss:  58902.8359375\n",
      "Accuracy: 0.535240650177002  Loss:  50299.35546875\n",
      "Accuracy: 0.535240650177002  Loss:  63391.7109375\n",
      "Accuracy: 0.535240650177002  Loss:  50815.9453125\n",
      "Accuracy: 0.535240650177002  Loss:  44214.78125\n",
      "Accuracy: 0.535240650177002  Loss:  90967.4375\n",
      "Accuracy: 0.535240650177002  Loss:  46976.8828125\n",
      "Accuracy: 0.535240650177002  Loss:  72366.1015625\n",
      "Accuracy: 0.535240650177002  Loss:  44589.8046875\n",
      "Accuracy: 0.535240650177002  Loss:  62895.6484375\n",
      "Accuracy: 0.535240650177002  Loss:  60942.1875\n",
      "Accuracy: 0.535240650177002  Loss:  60265.5625\n",
      "Accuracy: 0.535240650177002  Loss:  93425.1640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.535240650177002  Loss:  75039.75\n",
      "Accuracy: 0.535240650177002  Loss:  85869.4375\n",
      "The best so-far Fitness value obtained by ACO at iteration  5 == 27820.17578125\n"
     ]
    }
   ],
   "source": [
    "runs=1\n",
    "avgLoss=0\n",
    "max1=float('inf')\n",
    "bPos=[]\n",
    "t=1\n",
    "for i in range(runs):\n",
    "    aco=ACO()\n",
    "    avgLoss=avgLoss+aco[0]\n",
    "    bPos=aco[1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intrusion_Detection_NSL_KDD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ant Colony Optimization algorithm  (ACOA) as an optimizer for training a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle # saving and loading trained model\n",
    "from os import path\n",
    "\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing library for support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "# importing library for K-neares-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# importing library for Linear Discriminant Analysis Model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# importing library for Quadratic Discriminant Analysis Model\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
    "from sklearn.metrics import classification_report # for generating a classification report of model\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from keras.layers import Dense # importing dense layer\n",
    "from keras.models import Sequential #importing Sequential layer\n",
    "from keras.models import model_from_json # saving and loading trained model\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# representation of model layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numpy.random import choice as np_choice\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>intrusion</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>normal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.782367</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.620982</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-1.161030</td>\n",
       "      <td>-1.035688</td>\n",
       "      <td>-1.321428</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.339648</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.809857</td>\n",
       "      <td>-1.389669</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.690846</td>\n",
       "      <td>-0.184522</td>\n",
       "      <td>-0.189235</td>\n",
       "      <td>-0.572083</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.472521</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>125968</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-1.184947</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>125969</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>0.977304</td>\n",
       "      <td>1.159389</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>125970</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>0.979238</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.893738</td>\n",
       "      <td>-0.773724</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>125971</td>\n",
       "      <td>0.523041</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>1.602664</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-1.094207</td>\n",
       "      <td>-0.972455</td>\n",
       "      <td>-1.366922</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>125972</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>-0.631929</td>\n",
       "      <td>-0.637209</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.492801</td>\n",
       "      <td>-0.349162</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     count  srv_serror_rate  serror_rate  \\\n",
       "0                0 -0.717045        -0.631929    -0.637209   \n",
       "1                1 -0.620982        -0.631929    -0.637209   \n",
       "2                2  0.339648         1.605104     1.602664   \n",
       "3                3 -0.690846        -0.184522    -0.189235   \n",
       "4                4 -0.472521        -0.631929    -0.637209   \n",
       "...            ...       ...              ...          ...   \n",
       "125968      125968  0.872361         1.605104     1.602664   \n",
       "125969      125969 -0.717045        -0.631929    -0.637209   \n",
       "125970      125970 -0.725778        -0.631929    -0.637209   \n",
       "125971      125971  0.523041         1.605104     1.602664   \n",
       "125972      125972 -0.725778        -0.631929    -0.637209   \n",
       "\n",
       "        dst_host_serror_rate  dst_host_srv_serror_rate  logged_in  \\\n",
       "0                  -0.639532                 -0.624871  -0.809262   \n",
       "1                  -0.639532                 -0.624871  -0.809262   \n",
       "2                   1.608759                  1.618955  -0.809262   \n",
       "3                  -0.572083                 -0.602433   1.235694   \n",
       "4                  -0.639532                 -0.624871   1.235694   \n",
       "...                      ...                       ...        ...   \n",
       "125968              1.608759                  1.618955  -0.809262   \n",
       "125969             -0.639532                 -0.624871  -0.809262   \n",
       "125970              0.979238                 -0.624871   1.235694   \n",
       "125971              1.608759                  1.618955  -0.809262   \n",
       "125972             -0.639532                 -0.624871   1.235694   \n",
       "\n",
       "        dst_host_same_srv_rate  dst_host_srv_count  same_srv_rate  ...  \\\n",
       "0                    -0.782367           -0.818890       0.771283  ...   \n",
       "1                    -1.161030           -1.035688      -1.321428  ...   \n",
       "2                    -0.938287           -0.809857      -1.389669  ...   \n",
       "3                     1.066401            1.258754       0.771283  ...   \n",
       "4                     1.066401            1.258754       0.771283  ...   \n",
       "...                        ...                 ...            ...  ...   \n",
       "125968               -0.938287           -0.818890      -1.184947  ...   \n",
       "125969                0.977304            1.159389       0.771283  ...   \n",
       "125970               -0.893738           -0.773724       0.771283  ...   \n",
       "125971               -1.094207           -0.972455      -1.366922  ...   \n",
       "125972               -0.492801           -0.349162       0.771283  ...   \n",
       "\n",
       "        flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  intrusion  \\\n",
       "0             0        0        0        0        1        0          1   \n",
       "1             0        0        0        0        1        0          1   \n",
       "2             1        0        0        0        0        0          0   \n",
       "3             0        0        0        0        1        0          1   \n",
       "4             0        0        0        0        1        0          1   \n",
       "...         ...      ...      ...      ...      ...      ...        ...   \n",
       "125968        1        0        0        0        0        0          0   \n",
       "125969        0        0        0        0        1        0          1   \n",
       "125970        0        0        0        0        1        0          1   \n",
       "125971        1        0        0        0        0        0          0   \n",
       "125972        0        0        0        0        1        0          1   \n",
       "\n",
       "        abnormal  normal     label  \n",
       "0              0       1    normal  \n",
       "1              0       1    normal  \n",
       "2              1       0  abnormal  \n",
       "3              0       1    normal  \n",
       "4              0       1    normal  \n",
       "...          ...     ...       ...  \n",
       "125968         1       0  abnormal  \n",
       "125969         0       1    normal  \n",
       "125970         0       1    normal  \n",
       "125971         1       0  abnormal  \n",
       "125972         0       1    normal  \n",
       "\n",
       "[125973 rows x 98 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"datasets/bin_data.csv\"\n",
    "bin_data=pd.read_csv(path)\n",
    "bin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "Imkkjtu_Fnzr"
   },
   "outputs": [],
   "source": [
    "X = bin_data.iloc[:,0:93].values # dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
    "Y = bin_data[['intrusion']].values # target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "gNx0tOV7FwfO"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset 75% for training and 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "9-5ChLnLEVqn"
   },
   "outputs": [],
   "source": [
    "def Fobj():\n",
    "    mlp = Sequential() # creating model\n",
    "    # adding input layer and first layer with 50 neurons\n",
    "    # X_train.shape is (94479, 93)\n",
    "    mlp.add(Dense(units=33, input_dim=X_train.shape[1], activation='relu'))#50x93=4650\n",
    "    # output layer with sigmoid activation\n",
    "    mlp.add(Dense(units=1,activation='sigmoid'))\n",
    "    return mlp\n",
    "# len(Fobj().get_weights()[1])\n",
    "# Fobj().get_weights()[0].flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=Fobj()\n",
    "# defining loss function, optimizer, metrics and then compiling model\n",
    "mlp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "dim=0;\n",
    "for i in range(len(mlp.get_weights())):# 4 for 4 array \n",
    "    dim=dim+mlp.get_weights()[i].flatten().shape[0]# 4650+50+50+1=4751\n",
    "# dim = 4751\n",
    "# print(math.sqrt(dim))\n",
    "N=20# Population size\n",
    "X=np.zeros((N,dim)) #(20, 4751)\n",
    "# print(X[:,:3])\n",
    "Fit=np.ones(N)*float('inf') #(20, 1)\n",
    "# print(Fit.reshape(N,1))\n",
    "bF=float('inf')\n",
    "bPos=[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wights and bias Y=XW+bias \n",
    "def setWeights(X):\n",
    "    Len=0\n",
    "    # X is each row data in datasets X and len is 4751\n",
    "    # len(mlp.layers is 2 each contain 4 array\n",
    "    for i in range(0,len(mlp.layers)):\n",
    "#         get Wights first from layers\n",
    "        a=mlp.layers[i].get_weights()[0].shape\n",
    "        weights=X[Len:(Len+mlp.layers[i].get_weights()[0].flatten().shape[0])]\n",
    "        weights=np.reshape(weights,a) \n",
    "        Len=Len+mlp.layers[i].get_weights()[0].flatten().shape[0]\n",
    "#         get bias first from layers\n",
    "        a=mlp.layers[i].get_weights()[1].shape\n",
    "        bias=X[Len:(Len+mlp.layers[i].get_weights()[1].flatten().shape[0])]\n",
    "        bias=np.reshape(bias,a)\n",
    "        Len=Len+mlp.layers[i].get_weights()[1].flatten().shape[0]\n",
    "        mlp.layers[i].set_weights([weights,bias])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_boundaries(X):\n",
    "    for j in range(dim):\n",
    "        if X[j]>U_bounds:\n",
    "            X[j]=(L_bounds+np.random.random(1)*(U_bounds-L_bounds))\n",
    "        elif  X[j]<L_bounds:\n",
    "            X[j]=(L_bounds+np.random.random(1)*(U_bounds-L_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_bounds=0;\n",
    "U_bounds=1;\n",
    "def initialization():\n",
    "    for i in range(N):\n",
    "        for j in range(dim):\n",
    "            X[i][j]=(L_bounds+np.random.rand(1)*(U_bounds-L_bounds))\n",
    "        setWeights(X[i,:])\n",
    "        print(\"------------Solution \",i,\"-------------\")\n",
    "        score=mlp.evaluate(X_train, y_train, verbose = 1) \n",
    "        Fit[i]= score[0]#loss\n",
    "        print(score[1])#accurcy\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get numner node visted and probility\n",
    "def pick_move(distances,pheromone, visited,alpha=1,beta=1):\n",
    "    all_inds = range(len(distances))\n",
    "    pheromone = np.copy(pheromone)\n",
    "    # print(pheromone)\n",
    "    pheromone[list(visited)] = 0\n",
    "    # print(pheromone[list(visited)])\n",
    "    row = pheromone ** alpha * (( 1.0 / distances) ** beta)\n",
    "    # h=f\"\"\"\n",
    "    # {pheromone} ** {alpha} * (( 1.0 / {dist}) ** {beta})\n",
    "    # \"\"\"\n",
    "    # print(h)\n",
    "    # print(row)\n",
    "    norm_row = row / row.sum()#probility\n",
    "    # print(norm_row)\n",
    "    move = np_choice(all_inds, 1, p=norm_row)[0]\n",
    "    return move #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get path each node\n",
    "def gen_path(distances,pheromone,start=0):\n",
    "    path = []\n",
    "    visited = set()\n",
    "    visited.add(start)\n",
    "    prev = start\n",
    "    for i in range(len(distances) - 1):\n",
    "        move = pick_move(distances[prev],pheromone[prev], visited)\n",
    "        path.append((prev, move))\n",
    "        prev = move\n",
    "        visited.add(move)\n",
    "        # print(f\"move: {move} prev:{prev} visited: {visited}\")\n",
    "        # print(f\"-- path {path}\")\n",
    "    path.append((prev, start)) # going back to where we started   \n",
    "    # print(f\"path {path}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance each node\n",
    "def gen_path_dist(distances,path):\n",
    "    total_dist = 0\n",
    "    for ele in path:\n",
    "          total_dist +=distances[ele]\n",
    "    #     print(f\"{ele} : {distances[ele]}\")\n",
    "    # print(f\"total_dist: {total_dist}\")\n",
    "    return total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance each node and path in all_path\n",
    "def gen_all_paths(distances,pheromone,n_ants):\n",
    "    all_paths = []\n",
    "    for i in range(n_ants):\n",
    "        path = gen_path(distances,pheromone)\n",
    "        all_paths.append((path, gen_path_dist(distances,path)))\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_pheronome(distances,pheromone ,all_paths, n_best, shortest_path):\n",
    "    # sorted the paths by distance\n",
    "    sorted_paths = sorted(all_paths, key=lambda x: x[1])\n",
    "    # print(f\"sorted_paths : {sorted_paths}\")\n",
    "    for path, dist in sorted_paths[:n_best]:\n",
    "        for move in path:\n",
    "            #update pheromone values \n",
    "            pheromone[move] += 1.0 / distances[move]\n",
    "    return pheromone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(distances, n_ants, n_best, n_iterations, decay):\n",
    "    all_inds = range(len(distances))\n",
    "    pheromone = np.ones(distances.shape) / len(distances)\n",
    "    shortest_path = None\n",
    "    all_time_shortest_path = (\"placeholder\", np.inf)\n",
    "    for i in range(n_iterations):\n",
    "        #get distance each node and path in all_path\n",
    "        all_paths = gen_all_paths(distances,pheromone,n_ants)\n",
    "        # print(f\"all_paths : {all_paths}\")\n",
    "        pheromone=spread_pheronome(distances,pheromone ,all_paths, n_best, shortest_path=shortest_path)\n",
    "        shortest_path = min(all_paths, key=lambda x: x[1])\n",
    "#         print (shortest_path)\n",
    "        # swap the smallest value of shortest_path\n",
    "        if shortest_path[1] < all_time_shortest_path[1]:\n",
    "            all_time_shortest_path = shortest_path            \n",
    "        pheromone = pheromone * decay \n",
    "    return all_time_shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACO():\n",
    "  initialization()\n",
    "  Max_iter=5;\n",
    "  eo=list()\n",
    "  bF=float('inf')\n",
    "  bPos=[]\n",
    "  for i in range(5):\n",
    "    if Fit[i]<bF:\n",
    "        bF=Fit[i]\n",
    "        bPos=copy.copy(X[i]);\n",
    "  t=0\n",
    "  while t<Max_iter:\n",
    "    for i in range(N):\n",
    "        NewX=copy.copy(X[i]);\n",
    "        distances=X[i].reshape((56,56))\n",
    "#         print(distances)\n",
    "        shortest_path = run(distances, 1, 1, 5, 0.95)\n",
    "#         print (\"shorted_path: {}\".format(shortest_path))\n",
    "#         print(\"$\"*70)\n",
    "        NewX[i]=(shortest_path[1])\n",
    "#         check_boundaries(sh_p[j])\n",
    "        setWeights(NewX)\n",
    "        score = mlp.evaluate(X_train, y_train, verbose = 0)\n",
    "        print(\"Accuracy:\",score[1],\" Loss: \",score[0])\n",
    "        newFit= score[0]\n",
    "        if newFit<Fit[i]:\n",
    "            Fit[i]=newFit\n",
    "            X[i]=copy.copy(NewX);\n",
    "        if Fit[i]<bF:\n",
    "            bF=Fit[i]\n",
    "            bPos=copy.copy(X[i]);\n",
    "    t=t+1;\n",
    "    print(\"The best so-far Fitness value obtained by ACO at iteration \",t,\"==\",bF)\n",
    "  eo.append(bF);\n",
    "  eo.append(bPos)\n",
    "  return eo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Solution  0 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 270292.4062 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  1 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 268256.6250 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  2 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 301320.1250 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  3 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 241657.4375 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  4 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 273313.0000 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  5 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 197893.2656 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  6 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 340079.0000 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  7 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 193052.0625 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  8 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 272973.0312 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  9 -------------\n",
      "2953/2953 [==============================] - 7s 3ms/step - loss: 204364.6250 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  10 -------------\n",
      "2953/2953 [==============================] - 7s 2ms/step - loss: 199367.9688 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  11 -------------\n",
      "2953/2953 [==============================] - 7s 2ms/step - loss: 237086.4688 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  12 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 266531.0000 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  13 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 202121.3594 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  14 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 200572.2344 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  15 -------------\n",
      "2953/2953 [==============================] - 5s 2ms/step - loss: 209449.0781 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  16 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 273022.0312 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  17 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 217719.9375 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  18 -------------\n",
      "2953/2953 [==============================] - 6s 2ms/step - loss: 197058.4688 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "------------Solution  19 -------------\n",
      "2953/2953 [==============================] - 8s 3ms/step - loss: 193288.5781 - accuracy: 0.5352\n",
      "0.535240650177002\n",
      "Accuracy: 0.535240650177002  Loss:  288402.5625\n",
      "Accuracy: 0.535240650177002  Loss:  425328.5\n",
      "Accuracy: 0.535240650177002  Loss:  456722.375\n",
      "Accuracy: 0.535240650177002  Loss:  341340.15625\n",
      "Accuracy: 0.535240650177002  Loss:  296741.5\n",
      "Accuracy: 0.535240650177002  Loss:  246329.296875\n",
      "Accuracy: 0.535240650177002  Loss:  475234.625\n",
      "Accuracy: 0.535240650177002  Loss:  235454.3125\n",
      "Accuracy: 0.535240650177002  Loss:  419233.375\n",
      "Accuracy: 0.535240650177002  Loss:  234627.71875\n",
      "Accuracy: 0.535240650177002  Loss:  293614.96875\n",
      "Accuracy: 0.535240650177002  Loss:  504502.53125\n",
      "Accuracy: 0.535240650177002  Loss:  284293.3125\n",
      "Accuracy: 0.535240650177002  Loss:  350074.84375\n",
      "Accuracy: 0.535240650177002  Loss:  370813.4375\n",
      "Accuracy: 0.535240650177002  Loss:  227320.59375\n",
      "Accuracy: 0.535240650177002  Loss:  347671.9375\n",
      "Accuracy: 0.535240650177002  Loss:  223182.421875\n",
      "Accuracy: 0.535240650177002  Loss:  361997.59375\n",
      "Accuracy: 0.535240650177002  Loss:  229968.1875\n",
      "The best so-far Fitness value obtained by ACO at iteration  1 == 193052.0625\n",
      "Accuracy: 0.535240650177002  Loss:  288546.40625\n",
      "Accuracy: 0.535240650177002  Loss:  401653.5625\n",
      "Accuracy: 0.535240650177002  Loss:  461842.125\n",
      "Accuracy: 0.535240650177002  Loss:  323347.625\n",
      "Accuracy: 0.535240650177002  Loss:  297274.21875\n",
      "Accuracy: 0.535240650177002  Loss:  240459.796875\n",
      "Accuracy: 0.535240650177002  Loss:  519588.75\n",
      "Accuracy: 0.535240650177002  Loss:  246881.734375\n",
      "Accuracy: 0.535240650177002  Loss:  430206.46875\n",
      "Accuracy: 0.535240650177002  Loss:  224340.1875\n",
      "Accuracy: 0.535240650177002  Loss:  325692.21875\n",
      "Accuracy: 0.535240650177002  Loss:  468490.6875\n",
      "Accuracy: 0.535240650177002  Loss:  291826.1875\n",
      "Accuracy: 0.535240650177002  Loss:  442546.78125\n",
      "Accuracy: 0.535240650177002  Loss:  328583.78125\n",
      "Accuracy: 0.535240650177002  Loss:  228597.734375\n",
      "Accuracy: 0.535240650177002  Loss:  366594.28125\n",
      "Accuracy: 0.535240650177002  Loss:  224365.703125\n",
      "Accuracy: 0.535240650177002  Loss:  384942.09375\n",
      "Accuracy: 0.535240650177002  Loss:  222677.640625\n",
      "The best so-far Fitness value obtained by ACO at iteration  2 == 193052.0625\n",
      "Accuracy: 0.535240650177002  Loss:  287311.28125\n",
      "Accuracy: 0.535240650177002  Loss:  422929.21875\n",
      "Accuracy: 0.535240650177002  Loss:  439257.46875\n",
      "Accuracy: 0.535240650177002  Loss:  350529.96875\n",
      "Accuracy: 0.535240650177002  Loss:  296199.625\n",
      "Accuracy: 0.535240650177002  Loss:  252270.46875\n",
      "Accuracy: 0.535240650177002  Loss:  475251.5\n",
      "Accuracy: 0.535240650177002  Loss:  237517.703125\n",
      "Accuracy: 0.535240650177002  Loss:  378095.875\n",
      "Accuracy: 0.535240650177002  Loss:  235537.234375\n",
      "Accuracy: 0.535240650177002  Loss:  327138.28125\n",
      "Accuracy: 0.535240650177002  Loss:  487129.0625\n",
      "Accuracy: 0.535240650177002  Loss:  288263.78125\n",
      "Accuracy: 0.535240650177002  Loss:  393118.0625\n",
      "Accuracy: 0.535240650177002  Loss:  363819.125\n",
      "Accuracy: 0.535240650177002  Loss:  232932.40625\n",
      "Accuracy: 0.535240650177002  Loss:  369288.0\n",
      "Accuracy: 0.535240650177002  Loss:  223495.71875\n",
      "Accuracy: 0.535240650177002  Loss:  390114.09375\n",
      "Accuracy: 0.535240650177002  Loss:  216549.640625\n",
      "The best so-far Fitness value obtained by ACO at iteration  3 == 193052.0625\n",
      "Accuracy: 0.535240650177002  Loss:  287198.375\n",
      "Accuracy: 0.535240650177002  Loss:  406370.78125\n",
      "Accuracy: 0.535240650177002  Loss:  394369.0625\n",
      "Accuracy: 0.535240650177002  Loss:  324997.3125\n",
      "Accuracy: 0.535240650177002  Loss:  298337.21875\n",
      "Accuracy: 0.535240650177002  Loss:  245008.03125\n",
      "Accuracy: 0.535240650177002  Loss:  490111.40625\n",
      "Accuracy: 0.535240650177002  Loss:  235735.703125\n",
      "Accuracy: 0.535240650177002  Loss:  395045.78125\n",
      "Accuracy: 0.535240650177002  Loss:  226194.84375\n",
      "Accuracy: 0.535240650177002  Loss:  289656.46875\n",
      "Accuracy: 0.535240650177002  Loss:  489918.4375\n",
      "Accuracy: 0.535240650177002  Loss:  290376.0625\n",
      "Accuracy: 0.535240650177002  Loss:  451686.625\n",
      "Accuracy: 0.535240650177002  Loss:  344489.96875\n",
      "Accuracy: 0.535240650177002  Loss:  228040.0\n",
      "Accuracy: 0.535240650177002  Loss:  388204.75\n",
      "Accuracy: 0.535240650177002  Loss:  222616.625\n",
      "Accuracy: 0.535240650177002  Loss:  348613.8125\n",
      "Accuracy: 0.535240650177002  Loss:  222276.265625\n",
      "The best so-far Fitness value obtained by ACO at iteration  4 == 193052.0625\n",
      "Accuracy: 0.535240650177002  Loss:  287625.21875\n",
      "Accuracy: 0.535240650177002  Loss:  389265.09375\n",
      "Accuracy: 0.535240650177002  Loss:  452624.875\n",
      "Accuracy: 0.535240650177002  Loss:  323897.65625\n",
      "Accuracy: 0.535240650177002  Loss:  311256.03125\n",
      "Accuracy: 0.535240650177002  Loss:  255212.078125\n",
      "Accuracy: 0.535240650177002  Loss:  539884.0625\n",
      "Accuracy: 0.535240650177002  Loss:  236067.5625\n",
      "Accuracy: 0.535240650177002  Loss:  409974.09375\n",
      "Accuracy: 0.535240650177002  Loss:  236729.40625\n",
      "Accuracy: 0.535240650177002  Loss:  304839.625\n",
      "Accuracy: 0.535240650177002  Loss:  478640.6875\n",
      "Accuracy: 0.535240650177002  Loss:  283214.90625\n",
      "Accuracy: 0.535240650177002  Loss:  443903.03125\n",
      "Accuracy: 0.535240650177002  Loss:  386135.71875\n",
      "Accuracy: 0.535240650177002  Loss:  233105.40625\n",
      "Accuracy: 0.535240650177002  Loss:  358253.75\n",
      "Accuracy: 0.535240650177002  Loss:  222490.421875\n",
      "Accuracy: 0.535240650177002  Loss:  430071.375\n",
      "Accuracy: 0.535240650177002  Loss:  224653.90625\n",
      "The best so-far Fitness value obtained by ACO at iteration  5 == 193052.0625\n"
     ]
    }
   ],
   "source": [
    "runs=1\n",
    "avgLoss=0\n",
    "max1=float('inf')\n",
    "bPos=[]\n",
    "t=1\n",
    "for i in range(runs):\n",
    "    aco=ACO()\n",
    "    avgLoss=avgLoss+aco[0]\n",
    "    bPos=aco[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization()\n",
    "# v=X[0].reshape((56,56))\n",
    "# v.shape\n",
    "# v=X[:2434,:20]\n",
    "# print(v.shape)\n",
    "# X[:-20+4320:400,:20]\n",
    "# distances=X[i].reshape(50,95)\n",
    "# print(X[i].shape)\n",
    "# print(distances)\n",
    "# shortest_path = run(X, 1, 1, 10, 0.95)\n",
    "# print (\"shorted_path: {}\".format(shortest_path))\n",
    "\n",
    "\n",
    "\n",
    "#     for i in range(20,X.shape[1],N):\n",
    "#         distances=X[:i,:20]\n",
    "# #         print(distances)\n",
    "#         shortest_path = run(distances, 1, 1, 10, 0.95)\n",
    "# #         print (\"shorted_path: {}\".format(shortest_path))\n",
    "#         sh_p.append(shortest_path[1])\n",
    "#     print(len(sh_p))\n",
    "#     print(min(sh_p))\n",
    "#     sh_p= sorted(sh_p)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intrusion_Detection_NSL_KDD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
